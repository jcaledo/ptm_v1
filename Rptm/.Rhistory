0.00831 * Te -> RT
H <- 50 - RT
Te <- 298
Ea <- 100
0.00831 * Te -> RT
H <- 50 - RT
Te <- 308
Ea <- 100
0.00831 * Te -> RT
H <- 50 - RT
Ea <- 100
0.00831 * Te -> RT
H <- Ea - RT
Te <- 298
Ea <- 100
0.00831 * Te -> RT
H <- Ea - RT
rm(list =ls())
install.packages("topGO")
BiocManager::install("topGO")
library(ptm)
knitr::opts_chunk$set(echo = TRUE)
library(ptm)
library(knitr)
all <- meto.search(organism = 'Homo sapiens',
oxidant = 'hydrogen peroxide')
vivo <- unique(all$prot_id[which(all$met_vivo_vitro == 'vivo')])
bg <- unique(all$prot_id)
filevivo <- tempfile(pattern = 'vivo', fileext = '.txt')
for (i in 1:length(vivo)){
cat(vivo[i], "\n", file = filevivo, append = TRUE)
}
filebg <- tempfile(pattern = 'bg', fileext = '.txt')
for (i in 1:length(bg)){
cat(bg[i], "\n", file = filebg, append = TRUE)
}
vv <- go.enrich(s_file = filevivo, bg_file = filebg, aspect = 'BP', n = 20)
aspect = 'BP'
n = 20
s_file <- filevivo
## ----- The sample to be analyzed
sample <- read.csv(s_file, header = FALSE)
View(sample)
sample <- sample$V1 # as factor values array
sample
## ----- Geting GO ids for the backgraound set
bg <- read.csv(bg_file, header = FALSE)
bg_file <- filebg
## ----- Geting GO ids for the backgraound set
bg <- read.csv(bg_file, header = FALSE)
names(bg) <- 'up_id'
bg
bg$GO_id <- NA
for (i in 1:nrow(bg)){
bg$GO_id[i] <- get.go(bg$up_id[i], format = 'string')
}
i
bg$up_id[i]
get.go(bg$up_id[i], format = 'string')
View(bg)
str(bg$up_id)
bg[1]
bg$up_id[1]
i
get.go(as.character(bg$up_id[i]), format = 'string')
get.go('P01009', format = 'string')
rm(list = ls())
filevivo
all <- meto.search(organism = 'Homo sapiens',
oxidant = 'hydrogen peroxide')
bg <- unique(all$prot_id)
names(bg) <- 'up_id'
bg$GO_id <- NA
getwd()
bg <- unique(all$prot_id)
for (i in 1:length(bg)){
cat(bg[i], "\n", file = '/Users/JCA/ptm_outdropbox/ptm/htdocs/Rmd/go/GObackground.txt', append = TRUE)
}
vv <- go.enrich(s_file = filevivo, bg_file = filebg, aspect = 'BP', n = 20)
for (i in 1:length(bg)){
cat(bg[i], "\n", file = '/Users/JCA/ptm_outdropbox/ptm/htdocs/Rmd/go/GObackground.txt', append = TRUE)
}
# vv <- go.enrich(s_file = filevivo, bg_file = filebg, aspect = 'BP', n = 20)
bg_file <- '/Users/JCA/ptm_outdropbox/ptm/htdocs/Rmd/go/GObackground.txt'
## ----- Geting GO ids for the backgraound set
bg <- read.csv(bg_file, header = FALSE)
View(bg)
View(bg)
View(bg)
rm(bg)
for (i in 1:length(bg)){
cat(bg[i], "\n", file = '/Users/JCA/ptm_outdropbox/ptm/htdocs/Rmd/go/GObackground.txt', append = TRUE)
}
b <- unique(all$prot_id)
for (i in 1:length(b)){
cat(b[i], "\n", file = '/Users/JCA/ptm_outdropbox/ptm/htdocs/Rmd/go/GObackground.txt', append = TRUE)
}
knitr::opts_chunk$set(echo = TRUE)
library(ptm)
library(knitr)
all <- meto.search(organism = 'Homo sapiens',
oxidant = 'hydrogen peroxide')
vivo <- unique(all$prot_id[which(all$met_vivo_vitro == 'vivo')])
bg <- unique(all$prot_id)
target <- vivo
background <- bg
## ----- The sample to be analyzed
if (is.character(target) & length(target) == 1){ # input as path to the txt
if (gregexpr('txt', target)[[1]] != -1){
sample <- read.csv(target, header = FALSE)
sample <- trimws(as.character(sample$V1))
} else {
stop("A proper path to a txt file should be provided for the target set")
}
} else if (is.character(target) & length(target) > 1){ # input as vector
sample <- trimws(as.character(target))
} else if (is.data.frame(target) & nrow(target) > 1){ # input as dataframe
sample <- trimws(as.character(target))
} else {
stop("A proper target set must be provided")
}
## ----- The background set
if (is.character(background) & length(background) == 1){ # input as path to the txt
if (gregexpr('txt', background)[[1]] != -1){
bg <- read.csv(background, header = FALSE)
bg <- trimws(as.character(bg$V1))
} else {
stop("A proper path to a txt file should be provided for the background set")
}
} else if (is.character(background) & length(background) > 1){ # input as vector
bg <- as.character(background)
} else if (is.data.frame(background) & nrow(background) > 1){ # input as dataframe
bg <- trimws(as.character(background))
} else {
stop("A proper background set must be provided")
}
## ----- Check that the target is included into the background set
sample_bg <- intersect(sample, bg)
if (length(sample) != sum(sample_bg == sample)){
stop("Please, make sure that all the target proteins are contained in the background set")
}
## ----- Geting GO ids for the backgraound set
bg <- data.frame(up_id = bg, GO_id = rep(NA, length(bg)))
for (i in 1:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
bg$up_id[i]
View(bg)
a <- get.go(trimws(bg$up_id[i]), format = 'string')
e <- get.go(id = 'P00367') # requires removing spurius rows
## ------------------------- Subfunction for filtered list --------------------- ##
filtered.list <- function(id){
baseURL <- 'https://www.uniprot.org/uniprot/?query='
requestURL <- paste(baseURL, id, '&format=tab&columns=id%2Cgo', sep = "")
resp <- .get.url(requestURL)
cont <- httr::content(resp, 'text')
a <- strsplit(cont, split = '\n')[[1]] # all the lines
b <- a[which(grepl(id, a))]
c <- strsplit(b, split = "\t")[[1]][2] # only term names and GO ids
d <-  strsplit(c, split = ";")[[1]] # a single line by term
output <- as.data.frame(matrix(rep(NA,length(d)*2), ncol = 2))
names(output) <- c('term_name', 'GO_id')
for (i in 1:length(d)){
output$term_name[i] <- trimws( strsplit(d[i], split = '\\[')[[1]][1] )
output$GO_id[i] <- gsub('\\]', '', strsplit(d[i], split = '\\[')[[1]][2])
}
if (sum(is.na(output$GO_id)) == nrow(output)){
return(paste("Sorry, no GO terms found for the ", id, " entry", sep = ""))
} else {
output$obsolete <- output$definition_text <- output$aspect <- NA
for (i in 1:nrow(output)){
t <- strsplit(output$GO_id[i], split = ":")[[1]][2]
url <- 'https://www.ebi.ac.uk/QuickGO/services/ontology/go/search?query=GO%3A'
call <- paste(url, t, '&limit=1&page=1', sep = "")
resp <- .get.url(call)
cont <- httr::content(resp, 'text')
cont <- jsonlite::fromJSON(cont, flatten = TRUE)$results
if ("isObsolete" %in% names(cont)){
output$obsolete[i] <- cont$isObsolete
}
if ("definition.text" %in% names(cont)){
output$definition_text[i] <- cont$definition.text
}
if ("aspect" %in% names(cont)){
output$aspect[i] <- cont$aspect
}
}
}
return(output)
}
e <- filtered.list(background[i])
background[i]
e <- filtered.list(background[i])
library(ptm)
e <- filtered.list(background[i])
library(ptm)
e <- get.go(id = 'P00367') # requires removing spurius rows
View(e)
?ifelse
library(ptm)
rm(e)
e <- get.go(id = 'P00367') # requires removing spurius rows
View(e)
s <- 1:10
p <- 1:9
s + p
s <- data.frame(n=1:10)
View(s)
p
s$nn <- NA
s$nn <- p
rm(s,e)
library(ptm)
e <- get.go(id = 'P00367') # requires removing spurious rows
View(e)
for (i in 217:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
background[i]
get.go("Q14687", format = 'string')
View(e)
?get.url
View(bg)
View(e)
get.go <- function(id, filter = TRUE, format = 'dataframe', silent = FALSE){
if (!silent){
print(paste("Getting GO terms for ", id, sep = ""))
}
## ------------------------- Subfunction for complet list ---------------------- ##
complet.list <- function(id){
requestURL <- paste("https://www.ebi.ac.uk/QuickGO/services/annotation/",
"downloadSearch?includeFields=goName&selectedFields=symbol&geneProductId=",
id, sep = "")
r <- httr::GET(requestURL, httr::accept("text/gpad"))
httr::stop_for_status(r)
content <- httr::content(r,as = "text")
a <- strsplit(content, split = "\n")[[1]]
lines <- a[10:length(a)]
output <- as.data.frame(matrix(rep(NA, length(lines)*8), ncol = 8))
names(output) <- c('gene_product', 'qualifier', 'GO_id', 'evidence', 'evidence_code',
'reference', 'assigned_by', 'date')
for (i in seq_len(length(lines))){
t <- strsplit(lines[i], split = "\t")[[1]]
output$gene_product[i] <- t[2]
output$qualifier[i] <- t[3]
output$GO_id[i] <- t[4]
output$evidence[i] <- t[6]
output$evidence_code[i] <- strsplit(t[12], split = "=")[[1]][2]
output$reference[i] <- t[5]
output$assigned_by[i] <- t[10]
output$date[i] <- t[9]
}
return(output)
}
## ------------------------- Subfunction for filtered list --------------------- ##
filtered.list <- function(id){
baseURL <- 'https://www.uniprot.org/uniprot/?query='
requestURL <- paste(baseURL, id, '&format=tab&columns=id%2Cgo', sep = "")
resp <- .get.url(requestURL)
cont <- httr::content(resp, 'text')
a <- strsplit(cont, split = '\n')[[1]] # all the lines
b <- a[which(grepl(id, a))]
c <- strsplit(b, split = "\t")[[1]][2] # only term names and GO ids
d <-  strsplit(c, split = ";")[[1]] # a single line by term
if (length(d) < 2){
stop(print(d))
}
output <- as.data.frame(matrix(rep(NA,length(d)*2), ncol = 2))
names(output) <- c('term_name', 'GO_id')
for (i in 1:length(d)){
output$term_name[i] <- trimws( strsplit(d[i], split = '\\[')[[1]][1] )
output$GO_id[i] <- gsub('\\]', '', strsplit(d[i], split = '\\[')[[1]][2])
}
## ---- Removing spurious rows if necessary
output <- output[which(substr(output$GO_id, 1, 2) == "GO"), ]
if (sum(is.na(output$GO_id)) == nrow(output)){
return(paste("Sorry, no GO terms found for the ", id, " entry", sep = ""))
} else {
output$obsolete <- output$definition_text <- output$aspect <- NA
for (i in 1:nrow(output)){
t <- strsplit(output$GO_id[i], split = ":")[[1]][2]
url <- 'https://www.ebi.ac.uk/QuickGO/services/ontology/go/search?query=GO%3A'
call <- paste(url, t, '&limit=1&page=1', sep = "")
resp <- .get.url(call)
cont <- httr::content(resp, 'text')
cont <- jsonlite::fromJSON(cont, flatten = TRUE)$results
if ("isObsolete" %in% names(cont)){
output$obsolete[i] <- cont$isObsolete
}
if ("definition.text" %in% names(cont)){
output$definition_text[i] <- cont$definition.text
}
if ("aspect" %in% names(cont)){
output$aspect[i] <- cont$aspect
}
}
}
return(output)
}
## ------- Building the output dataframe ----------------- ##
if (filter){
output <- filtered.list(id)
} else {
output <- complet.list(id)
}
if (format == 'string'){
output <- paste(output$GO_id, collapse = ", ")
}
return(output)
}
p <- get.go(background[i])
library(ptm)
p <- get.go(background[i])
library(ptm)
p <- get.go(background[i])
p <- get.go('P01009')
p <- ptm::get.go('P01009')
p <- ptm::get.go(background[i])
library(ptm)
p <- ptm::get.go(background[i])
background[i]
f <- get.go(id = 'P00367') # no GO terms found
p
get.go(trimws(bg$up_id[i]), format = 'string')
q <- get.go('Q14687')
q <- ptm::get.go('Q14687')
get.go(trimws(bg$up_id[i]), format = 'string')
ptm::get.go(trimws(bg$up_id[i]), format = 'string')
ptm::get.go(trimws('Q14687'), format = 'string')
ptm::get.go('Q14687', format = 'string')
library(ptm)
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- ptm::get.go(trimws(bg$up_id[i]), format = 'string')
}
library(ptm)
library(ptm)
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- ptm::get.go(trimws(bg$up_id[i]), format = 'string')
}
?get.go
get.go()
get.go
devtools::load_all(".")
devtools::load_all(".")
rm(get.go)
rm(filtered.list)
library(ptm)
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
get.go(trimws(bg$up_id[i]), format = 'string')
library(ptm)
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
get.go(trimws(bg$up_id[i]), format = 'string')
get.go(trimws(bg$up_id[i]))
get.go(trimws(bg$up_id[i])) -> p
p
p$GO_id
atomic(p)
is.atomic(p)
library(ptm)
for (i in 669:nrow(bg)){
print(i)
bg$GO_id[i] <- get.go(trimws(bg$up_id[i]), format = 'string')
}
View(bg)
bg_proteins <- bg$up_id
getwd()
write.table(bg, file = "file_temp.map", quote = FALSE,
sep = "\t", row.names = FALSE, col.names = FALSE)
bg2GO <- topGO::readMappings(file = 'file_temp.map')
bg_proteins <- names(bg2GO)
file.remove("file_temp.map")
## ------- Compare sample vs bg_proteins
# It is essential that the items in the 'sample' vector
# correspond to items within the background ie 'bg_proteins'
compared_proteins <- factor(as.integer(bg_proteins %in% sample))
names(compared_proteins) <- bg_proteins
## ------- Create topGO object
GOdata <- new("topGOdata", ontology = aspect, allGenes = compared_proteins,
annot = annFUN.gene2GO, gene2GO = bg2GO)
save(bg, file = './bg.Rda')
aspect = 'BP'
## ------- Create topGO object
GOdata <- new("topGOdata", ontology = aspect, allGenes = compared_proteins,
annot = annFUN.gene2GO, gene2GO = bg2GO)
library(topGO)
## ------- Create topGO object
GOdata <- new("topGOdata", ontology = aspect, allGenes = compared_proteins,
annot = annFUN.gene2GO, gene2GO = bg2GO)
## ------- Run Fisher test
resultFisher <- topGO::runTest(GOdata, algorithm = "classic", statistic = "fisher")
n = 20
## --- Create table with enrichment result
output <- topGO::GenTable(GOdata, classicFisher = resultFisher, topNodes = n)
output <- as.data.frame(output)
View(output)
a <- gorilla(target = './go/GOvivo.txt')
devtools::load_all(".")
a <- gorilla(target = './go/GOvivo.txt')
getwd()
setwd("./test/testthat")
setwd("./tests/testthat")
a <- gorilla(target = './go/GOvivo.txt')
expect_is(a, 'data.frame')
expect_gt(nrow(a), 100)
expect_gt(ncol(a), 8)
b <- gorilla(target = './go/GOvivo.txt', db = 'all')
expect_is(b, 'list')
expect_equal(length(b), 3)
expect_is(b[[1]], 'data.frame')
expect_gt(nrow(b[[1]]), 10)
expect_equal(ncol(b[[1]]), 10)
expect_is(b[[2]], 'data.frame')
expect_gt(nrow(b[[2]]), 10)
expect_equal(ncol(b[[2]]), 10)
expect_is(b[[3]], 'data.frame')
expect_gt(nrow(b[[3]]), 10)
expect_equal(ncol(b[[3]]), 10)
c <- gorilla(target = './go/GOvivo.txt',
background = './go/GObackground.txt',
mode = 'hg')
expect_is(c, 'data.frame')
expect_gt(nrow(c), 100)
expect_gt(ncol(c), 8)
d <- gorilla(target = './go/GOvivo.txt',
background = './go/GObackground.txt',
db = 'func', mode = 'hg')
expect_is(c, 'data.frame')
expect_gt(nrow(c), 100)
expect_gt(ncol(c), 8)
expect_is(d, 'data.frame')
expect_gt(nrow(d), 100)
expect_gt(nrow(d), 50)
expect_gt(ncol(d), 8)
e <- gorilla(target = './go/GOvivo.txt',
background = './go/GObackground.txt',
db = 'comp', mode = 'hg')
expect_is(e, 'data.frame')
expect_gt(nrow(e), 100)
expect_gt(ncol(e), 8)
f <- gorilla(target = './go/GOvivo.txt',
background = './go/GObackground.txt',
db = 'all', mode = 'hg')
expect_is(f, 'list')
expect_equal(length(f), 3)
expect_is(f[[1]], 'data.frame')
expect_gt(nrow(f[[1]]), 10)
expect_equal(ncol(f[[1]]), 10)
expect_is(f[[2]], 'data.frame')
expect_gt(nrow(f[[2]]), 10)
expect_equal(ncol(f[[2]]), 10)
expect_is(f[[3]], 'data.frame')
expect_gt(nrow(f[[3]]), 10)
expect_equal(ncol(f[[3]]), 10)
?get.seq
rm(list = ls())
a <- background.go(ids = "./go/id_set.txt")
b <-  background.go(ids = c("Q13015", "Q14667", "P08575", "Q5JSZ5", "P13196", "H7C4H7"))
expect_is(a, 'data.frame')
expect_equal(nrow(a), 6)
expect_equal(ncol(a), 2)
expect_is(b, 'data.frame')
expect_equal(nrow(b), 6)
expect_equal(ncol(b), 2)
expect_equal(a, b)
a
b
View(a)
View(b)
View(a)
View(b)
View(a)
devtools::load_all("~/ptm_outdropbox/ptm/Rptm")
library(ptm)
library(ptm)
library(devtools)
devtools::check_win_devel(pkg = ".",
args = NULL,
manual = TRUE,
email = NULL,
quiet = FALSE)
?read.csv
?read.delim
devtools::run_examples(pkg = ".",
start = NULL,
run_dontrun = FALSE,
run_donttest = FALSE,
document = TRUE)
devtools::run_examples(pkg = ".",
start = NULL,
run_dontrun = FALSE,
run_donttest = FALSE,
document = TRUE)
devtools::load_all("~/ptm_outdropbox/ptm/Rptm")
devtools::load_all(".")
